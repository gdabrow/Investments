{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gdabrow/Investments/blob/main/stockAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSqkxcHVVWsC"
      },
      "source": [
        "## **Information on companies listed on stock exchanges obtained from:**\n",
        "\n",
        "* https://www.zacks.com/\n",
        "* https://finance.yahoo.com/\n",
        "* https://site.financialmodelingprep.com/\n",
        "* https://www.alphavantage.co/documentation/\n",
        "* https://finviz.com/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Installation and import of necessary libraries**"
      ],
      "metadata": {
        "id": "g5QiVjRb_9T1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqBcaPiNJvNV"
      },
      "outputs": [],
      "source": [
        "# installation libraries\n",
        "! pip install yfinance --upgrade --no-cache-dir &> /dev/null\n",
        "! pip install beautifulsoup4 &> /dev/null\n",
        "! pip install cloudscraper &> /dev/nul\n",
        "\n",
        "# import libraries\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import cloudscraper\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import random\n",
        "import json\n",
        "import time\n",
        "\n",
        "# complete the token\n",
        "fin_apikey = '...'\n",
        "\n",
        "scraper = cloudscraper.create_scraper(delay=10)\n",
        "\n",
        "# disk connection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Definitions of needed functions and objects**"
      ],
      "metadata": {
        "id": "dwucScyoq2NK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jQizoQAQQtl_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def read_csv_as_flat_list(filename: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    Reads a CSV file and returns a flat list containing all values.\n",
        "\n",
        "    Arguments:\n",
        "    filename (str): The path to the CSV file to be read.\n",
        "\n",
        "    Returns:\n",
        "    list: A flat list containing all values from the CSV file, where each list item\n",
        "    represents a single value from the file.\n",
        "\n",
        "    Example usage:\n",
        "    >>> data = read_csv_as_flat_list('your_file_name.csv')\n",
        "    >>> print(data)\n",
        "    \"\"\"\n",
        "\n",
        "    with open(filename, newline='') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        flat_list = [item for row in reader for item in row]\n",
        "    return flat_list\n",
        "\n",
        "\n",
        "\n",
        "def go_to_url(tickers: list[str], urls: list[str]) -> list[dict]:\n",
        "    \"\"\"\n",
        "    This function generates a list of dictionaries, each containing the stock symbol and corresponding URLs modified to include the ticker symbol.\n",
        "\n",
        "    Args:\n",
        "    tickers (list of str): A list of ticker symbols (e.g., ['AAPL', 'GOOG']).\n",
        "    urls (list of str): A list of URL templates (e.g., ['https://www.zacks.com/stock/quote/', 'https://www.tipranks.com/stocks/']).\n",
        "\n",
        "    Returns:\n",
        "    list of dicts: A list where each dictionary represents a ticker symbol and its associated URLs.\n",
        "                   Each key in the dictionary is the domain of the URL, and its value is the URL concatenated with the ticker symbol.\n",
        "    \"\"\"\n",
        "\n",
        "    www = []\n",
        "\n",
        "    for tic in tickers:\n",
        "        dic={'symbol': tic}\n",
        "\n",
        "        for url in urls:\n",
        "            netloc = urlparse(url).netloc\n",
        "            dic[netloc]= url + tic\n",
        "\n",
        "        www.append(dic)\n",
        "\n",
        "    www = pd.DataFrame(www)\n",
        "    www.set_index('symbol', inplace=True)\n",
        "\n",
        "    return www\n",
        "\n",
        "\n",
        "def conversion_to_number(dataframe: pd.DataFrame, columns: list) -> None:\n",
        "    \"\"\"\n",
        "    Convert specified columns in a pandas DataFrame from percentage strings to float.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): The DataFrame containing the columns to convert.\n",
        "        columns (list): A list of column names (strings) to be converted.\n",
        "\n",
        "    Note:\n",
        "        This function modifies the original DataFrame in place.\n",
        "\n",
        "    Example:\n",
        "        conversion_to_number(df, ['column1', 'column2'])\n",
        "    \"\"\"\n",
        "    # Check if the input is of correct types\n",
        "    if not isinstance(dataframe, pd.DataFrame):\n",
        "        raise ValueError(\"dataframe must be a pandas DataFrame\")\n",
        "    if not isinstance(columns, list):\n",
        "        raise ValueError(\"columns must be a list of column names\")\n",
        "\n",
        "    # Iterate through the specified columns and convert each from percentage string to float\n",
        "    for col in columns:\n",
        "        # Check if the column exists in the DataFrame\n",
        "        if col not in dataframe.columns:\n",
        "            raise ValueError(f\"Column {col} does not exist in the DataFrame\")\n",
        "        # Replace '%' with nothing and convert the type\n",
        "        dataframe[col] = dataframe[col].str.replace(\"%\", \"\").astype(float)\n",
        "\n",
        "\n",
        "def conversion_to_percent(dataframe: pd.DataFrame, columns: list) -> None:\n",
        "    \"\"\"\n",
        "    Convert selected columns of a DataFrame to percentages by multiplying them by 100.\n",
        "\n",
        "    Args:\n",
        "    dataframe (pd.DataFrame): The DataFrame containing the columns to be converted.\n",
        "    columns (list): A list of column names (strings) to be converted to percentages.\n",
        "\n",
        "    Returns:\n",
        "    None: The function modifies the DataFrame in place and does not return anything.\n",
        "\n",
        "    Raises:\n",
        "    KeyError: If any of the specified columns do not exist in the DataFrame.\n",
        "    TypeError: If the data in the columns is not numeric and cannot be converted to percentages.\n",
        "    \"\"\"\n",
        "    # Check if all columns exist in the DataFrame\n",
        "    missing_cols = [col for col in columns if col not in dataframe.columns]\n",
        "    if missing_cols:\n",
        "        raise KeyError(f\"The following columns are missing from the DataFrame: {missing_cols}\")\n",
        "\n",
        "    # Check if all specified columns are numeric\n",
        "    non_numeric_cols = [col for col in columns if not pd.api.types.is_numeric_dtype(dataframe[col])]\n",
        "    if non_numeric_cols:\n",
        "        raise TypeError(f\"The following columns are not numeric and cannot be converted to percentages: {non_numeric_cols}\")\n",
        "\n",
        "    # Convert columns to percentages\n",
        "    for col in columns:\n",
        "        dataframe[col] = dataframe[col] * 100\n",
        "        # Ensure the operation does not introduce unexpected types\n",
        "        dataframe[col] = dataframe[col].astype(float)\n",
        "\n",
        "# Note: The function call and any tests should be uncommented and run outside this code block to verify its functionality.\n",
        "\n",
        "\n",
        "\n",
        "def get_data_from_yf(tickers: list[str]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Fetches and processes financial data for a list of tickers from Yahoo Finance.\n",
        "\n",
        "    Args:\n",
        "        tickers (list of str): A list of stock ticker symbols.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A DataFrame containing processed Yahoo Finance data for the given tickers.\n",
        "    \"\"\"\n",
        "\n",
        "    yahoo_data = []  # Initialize an empty list to store data for each ticker\n",
        "\n",
        "    # Iterate over each ticker to fetch and process its data\n",
        "    for tic in tickers:\n",
        "        try:\n",
        "            data = yf.Ticker(tic).info  # Fetch data for the ticker\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to fetch Yahoo Finance data for {tic}: {e}\")\n",
        "            continue  # Skip to the next ticker if an error occurs\n",
        "\n",
        "        # Convert selected fields to percentages based on the regular market previous close price\n",
        "        try:\n",
        "            price = float(data['regularMarketPreviousClose'])  # Get the previous close price\n",
        "            # Map original field names to new percentage field names\n",
        "            percentage_fields = {\n",
        "                'targetLowPrice': 'Target low price [%]',\n",
        "                'targetMeanPrice': 'Target mean price [%]',\n",
        "                'targetMedianPrice': 'Target median price [%]',\n",
        "                'targetHighPrice': 'Target high price [%]'\n",
        "            }\n",
        "            for original, new in percentage_fields.items():\n",
        "                if original in data:\n",
        "                    # Convert the original price to a percentage change\n",
        "                    data[new] = round(100 * (float(data[original]) / price - 1), 2)\n",
        "                else:\n",
        "                    data[new] = None  # Set to None if the original field is missing\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to process percentage fields for {tic}: {e}\")\n",
        "            continue  # Skip to the next ticker if an error occurs\n",
        "\n",
        "        yahoo_data.append(data)  # Add the processed data to the list\n",
        "\n",
        "\n",
        "    yahoo_data = pd.DataFrame(yahoo_data)  # Convert the list of data to a DataFrame\n",
        "    yahoo_data.set_index('symbol', inplace=True)\n",
        "\n",
        "    return yahoo_data  # Return the processed DataFrame\n",
        "\n",
        "\n",
        "def get_data_from_zacks(tickers: list[str]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Fetches Zacks Investment Research rankings for a given list of stock symbols.\n",
        "\n",
        "    Args:\n",
        "        tickers (List[str]): List of stock symbols to fetch the ranking for.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing the Zacks ranking for each stock symbol.\n",
        "                      If the ranking is not available, returns 0 for that symbol.\n",
        "    \"\"\"\n",
        "\n",
        "    zacks = []\n",
        "    for tic in tickers:\n",
        "        url = f'https://www.zacks.com/stock/quote/{tic}'\n",
        "        try:\n",
        "            page = scraper.get(url)\n",
        "            page_html = BeautifulSoup(page.content, 'html.parser')\n",
        "            rank = page_html.find_all('span', class_=lambda x: x and x.startswith('rank_chip rankrect_'))\n",
        "            for r in rank:\n",
        "                if r.text.isdigit():\n",
        "                    zacks.append({'symbol' : tic, 'zacks' : int(r.text)})\n",
        "                    time.sleep(random.uniform(1, 3))  # Randomized delay to mimic human behavior\n",
        "\n",
        "        except:\n",
        "            zacks.append({'symbol' : tic, 'zacks' : 0})\n",
        "            time.sleep(random.uniform(1, 3))  # Randomized delay to mimic human behavior\n",
        "            continue\n",
        "\n",
        "    zacks = pd.DataFrame(zacks)\n",
        "    zacks.set_index('symbol', inplace=True)\n",
        "\n",
        "    return zacks\n",
        "\n",
        "\n",
        "def get_data_from_financialmodeling(tickers: list, fin_apikey: str) -> pd.DataFrame:\n",
        "\n",
        "    \"\"\"\n",
        "    Fetches and combines discounted cash flow and rating information for a list of tickers from the FinancialModelingPrep API.\n",
        "\n",
        "    Args:\n",
        "        tickers (list): A list of stock tickers (symbols) for which data is to be fetched.\n",
        "        fin_apikey (str): The API key required to authenticate requests to the FinancialModelingPrep API.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the combined data for all tickers, set with 'symbol' as the index.\n",
        "    \"\"\"\n",
        "\n",
        "    financialmodelin = []\n",
        "    for tic in tickers:\n",
        "\n",
        "        cdf_url = f'https://financialmodelingprep.com/api/v3/discounted-cash-flow/{tic}?apikey={fin_apikey}'\n",
        "        rating_url = f'https://financialmodelingprep.com/api/v3/rating/{tic}?apikey={fin_apikey}'\n",
        "\n",
        "\n",
        "        try:\n",
        "            cdf_response = urlopen(cdf_url)\n",
        "        except Exception as e:\n",
        "            print(f\"No data for {tic}: {e}\")\n",
        "            continue\n",
        "        cdf_data = json.loads(cdf_response.read().decode(\"utf-8\"))\n",
        "\n",
        "        if len(cdf_data) == 0:\n",
        "            cdf_data = [{'symbol': tic,\n",
        "                        'date': 'no data',\n",
        "                        'dcf': 0,\n",
        "                        'Stock Price': 0}]\n",
        "\n",
        "        try:\n",
        "            rating_response = urlopen(rating_url)\n",
        "        except Exception as e:\n",
        "            print(f\"No data for {tic}: {e}\")\n",
        "            continue\n",
        "\n",
        "        rating_data = json.loads(rating_response.read().decode(\"utf-8\"))\n",
        "\n",
        "        if len(rating_data) == 0:\n",
        "            rating_data = [{'symbol': tic,\n",
        "                            'date': 'no data',\n",
        "                            'rating': 'no data',\n",
        "                            'ratingScore': 0 ,\n",
        "                            'ratingRecommendation': 'no data',\n",
        "                            'ratingDetailsDCFScore': 0,\n",
        "                            'ratingDetailsDCFRecommendation': 'no data',\n",
        "                            'ratingDetailsROEScore': 0,\n",
        "                            'ratingDetailsROERecommendation': 'no data',\n",
        "                            'ratingDetailsROAScore': 0,\n",
        "                            'ratingDetailsROARecommendation': 'no data',\n",
        "                            'ratingDetailsDEScore': 0,\n",
        "                            'ratingDetailsDERecommendation': 'no data',\n",
        "                            'ratingDetailsPEScore': 0,\n",
        "                            'ratingDetailsPERecommendation': 'no data',\n",
        "                            'ratingDetailsPBScore': 0,\n",
        "                            'ratingDetailsPBRecommendation': 'no data'}]\n",
        "\n",
        "        financialmodelin.append({**cdf_data[0], **rating_data[0]})\n",
        "\n",
        "    financialmodelin = pd.DataFrame(financialmodelin)\n",
        "    financialmodelin.set_index('symbol', inplace=True)\n",
        "\n",
        "    return financialmodelin\n",
        "\n",
        "\n",
        "def get_data_from_finviz(tickers: list[str]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Fetches and returns financial data for a list of tickers from Finviz.\n",
        "\n",
        "    Args:\n",
        "        tickers (List[str]): A list of stock ticker symbols.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the financial data for each ticker,\n",
        "                      with each row representing a different ticker and columns for different financial metrics.\n",
        "                      The index of the DataFrame is set to the ticker symbols.\n",
        "    \"\"\"\n",
        "    # Initialize the list to hold data for all tickers\n",
        "    finviz_data = []\n",
        "\n",
        "    # List of user agents to rotate through for requests, to prevent request blocking by the server\n",
        "    USER_AGENTS_LIST = [\n",
        "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
        "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15\",\n",
        "        \"Mozilla/5.0 (iPad; CPU OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.3 Mobile/15E148 Safari/604.1\",\n",
        "        \"Mozilla/5.0 (Linux; Android 10; SM-G975F) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.92 Mobile Safari/537.36\",\n",
        "        \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:88.0) Gecko/20100101 Firefox/88.0\"\n",
        "    ]\n",
        "\n",
        "    # Loop through each ticker to scrape its data\n",
        "    for tic in tickers:\n",
        "        url = f'https://finviz.com/quote.ashx?t={tic}'\n",
        "        # Random choice of user-agent to prevent blocking\n",
        "        page = scraper.get(url, headers={'User-Agent': random.choice(USER_AGENTS_LIST)})\n",
        "        page_html = BeautifulSoup(page.content, 'html.parser')\n",
        "        table = page_html.find_all('tr', class_='table-dark-row')\n",
        "        # Delay to prevent being blocked by the server\n",
        "        time.sleep(random.uniform(1, 3))  # Randomized delay to mimic human behavior\n",
        "\n",
        "        # Skip tickers for which no data is available\n",
        "        if not table:\n",
        "            print(f'No data for {tic}')\n",
        "            continue\n",
        "\n",
        "        # Initialize lists for the names and values of data points\n",
        "        names, values = [], []\n",
        "\n",
        "        # Extract data from each row of the table\n",
        "        for row in table:\n",
        "            cells = row.find_all('td', class_='snapshot-td2')\n",
        "            for i, cell in enumerate(cells):\n",
        "                text = cell.text.strip() if cell.text.strip() != '-' else '0'  # Strip whitespace and convert '-' to '0'\n",
        "                if i % 2 == 0:  # Even index elements are names\n",
        "                    names.append(text)\n",
        "                else:  # Odd index elements are values\n",
        "                    values.append(text)\n",
        "\n",
        "        # Create a dictionary for the ticker's data and add it to the list\n",
        "        data = dict(zip(names, values))\n",
        "        data['Symbol'] = tic\n",
        "        finviz_data.append(data)\n",
        "\n",
        "    # Convert the list of data into a pandas DataFrame and set the index to the symbols\n",
        "    finviz_data = pd.DataFrame(finviz_data)\n",
        "    finviz_data.set_index('Symbol', inplace=True)\n",
        "\n",
        "    return finviz_data\n",
        "\n",
        "\n",
        "def get_selected_tickers_from_finviz(urls: list[str]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Scrapes given Finviz URLs for stock tickers.\n",
        "\n",
        "    Args:\n",
        "        urls (List[str]): A list of URLs to scrape for tickers.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A dataframe containing all found tickers.\n",
        "    \"\"\"\n",
        "    # Initialize an empty list to store tickers\n",
        "    tickers = []\n",
        "\n",
        "    # Loop through each URL\n",
        "    for url in urls:\n",
        "        # Scrape the page content\n",
        "        page = scraper.get(url)  # Assuming 'scraper' is a predefined variable, need to handle its definition.\n",
        "        page_html = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "        # Find all 'a' elements with class 'tab-link' and containing 'quote.ashx?t' in 'href'\n",
        "        for a in page_html.find_all('a', class_=\"tab-link\", href=True):\n",
        "            if 'quote.ashx?t' in a['href']:\n",
        "                # Add the ticker text to the list\n",
        "                tickers.append(a.text)\n",
        "\n",
        "    # Convert the list of tickers to a DataFrame\n",
        "    tickers = pd.DataFrame(tickers, columns=['ticker'])\n",
        "\n",
        "    # Return the DataFrame\n",
        "    return tickers\n",
        "\n",
        "\n",
        "def norm(series: pd.Series, max_value: float, reverse: bool = False) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Normalizes a Pandas Series by dividing all its values by a specified maximum value.\n",
        "    Optionally, reverses the series values by subtracting from the max_value and adds one before normalization.\n",
        "\n",
        "    Args:\n",
        "        series (Series): Pandas Series to be normalized.\n",
        "        max_value (float): The value used to normalize the series values.\n",
        "        reverse (bool, optional): Flag to determine if the series values should be reversed. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        Series: The normalized (and possibly reversed) Pandas Series.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If max_value is zero, to avoid division by zero.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if max_value is zero to prevent division by zero\n",
        "    if max_value == 0:\n",
        "        raise ValueError(\"max_value cannot be zero.\")\n",
        "\n",
        "    # If reverse is True, modify the series accordingly\n",
        "    if reverse:\n",
        "        series = -series + max_value + 1\n",
        "\n",
        "    # Normalize the series\n",
        "    normalized_series = series / max_value\n",
        "\n",
        "    # Ensure no values exceed 1.5 after normalization\n",
        "    normalized_series = normalized_series.clip(upper=1.5)\n",
        "\n",
        "    return normalized_series\n",
        "\n",
        "# name of the fields that will be retrieved from finance.yahoo\n",
        "COLUMNS_YF = ['exchange', 'country', 'industry', 'sector', 'currentPrice',\n",
        "              'trailingPE', 'forwardPE', 'pegRatio', 'trailingPegRatio', 'trailingEps', 'forwardEps',\n",
        "              'recommendationMean', 'recommendationKey', 'numberOfAnalystOpinions',\n",
        "              'targetHighPrice', 'targetLowPrice', 'targetMeanPrice', 'targetMedianPrice',\n",
        "              'Target low price [%]', 'Target mean price [%]', 'Target median price [%]', 'Target high price [%]',\n",
        "              'profitMargins', 'revenueGrowth', 'grossMargins', 'ebitdaMargins', 'quickRatio', 'currentRatio', 'earningsGrowth']\n",
        "\n",
        "# fields that will be renamed from from finance.yahoo for clarity\n",
        "COLUMNS_YF_TO_CHANGE = {'currentPrice':'Price', 'trailingPE':'Trailing PE', 'forwardPE':'Forward PE',\n",
        "                        'pegRatio':'PEG ratio', 'trailingPegRatio':'Trailing PEG ratio', 'trailingEps':'Trailing EPS',\n",
        "                        'forwardEps':'Forward Eps', 'recommendationMean':'Recommendation mean', 'recommendationKey':'Recommendation key',\n",
        "                        'numberOfAnalystOpinions':'Number of analyst', 'targetHighPrice':'Target high price', 'targetLowPrice':'Target low price',\n",
        "                        'targetMeanPrice':'Target mean price', 'targetMedianPrice':'Target median price', 'profitMargins':'Profit margins',\n",
        "                        'revenueGrowth':'Revenue growth', 'grossMargins':'Gross margins', 'ebitdaMargins':'Ebitda margins', 'quickRatio':'Quick ratio',\n",
        "                        'currentRatio':'Current rtio', 'earningsGrowth':'Earnings growth'}\n",
        "\n",
        "# fields that will be renamed from from financialmodelingprep.com for clarity\n",
        "COLUMNS_FINMOD_TO_CHANGE = {'rating':'Rating', 'ratingScore':'Rating score', 'ratingRecommendation':'Rating recommendation',\n",
        "                            'ratingDetailsDCFScore':'Rating DCF score', 'ratingDetailsDCFRecommendation':'Rrating DCF recommendation',\n",
        "                            'ratingDetailsROEScore':'Rating ROE score', 'ratingDetailsROERecommendation':'Rating ROE recommendation',\n",
        "                            'ratingDetailsROAScore':'Rating ROA score', 'ratingDetailsROARecommendation':'Rating ROA recommendation',\n",
        "                            'ratingDetailsDEScore':'Rating D/E score', 'ratingDetailsDERecommendation':'Rating DE recommendation',\n",
        "                            'ratingDetailsPEScore':'Rating P/E score', 'ratingDetailsPERecommendation':'Rating PE recommendation',\n",
        "                            'ratingDetailsPBScore':'Rating P/B score', 'ratingDetailsPBRecommendation':'Rating PB recommendation'}\n",
        "\n",
        "# name of the fields that will be retrieved from finviz.com\n",
        "COLUMNS_FIN = ['EPS this Y', 'EPS next Q','EPS next Y', 'EPS next 5Y', 'EPS past 5Y', 'PEG', 'ROA', 'ROE', 'ROI']\n",
        "\n",
        "# field names to convert to percentages\n",
        "COLUMNS_TO_PERCENT = ['Profit margins', 'Revenue growth', 'Gross margins','Earnings growth']\n",
        "\n",
        "# field names which will be shown in the report\n",
        "COLUMNS_TO_SHOW = ['exchange', 'country', 'industry', 'sector', 'Ranking', 'Price', 'Trailing PE', 'Number of analyst','Recommendation mean',\n",
        "                      'Recommendation key','Target low price [%]', 'Target mean price [%]', 'Target median price [%]',\n",
        "                      'Target high price [%]', 'zacks', 'tipranks', 'Quick ratio', 'Current rtio', 'EPS this Y', 'EPS next Y',\n",
        "                      'PEG', 'ROA', 'ROE', 'ROI', 'www.zacks.com',\t'www.tipranks.com']\n",
        "\n",
        "# names of fields for ranking with their parameters\n",
        "PARAMETERS_FOR_RANKING = [\n",
        "    {'series': 'Recommendation mean', 'max': 5, 'reverse': True, 'weight': 1.0},\n",
        "    {'series': 'Target mean price [%]', 'max': 25, 'reverse': False, 'weight': 1.2},\n",
        "    {'series': 'Target median price [%]', 'max': 25, 'reverse': False, 'weight': 1.2},\n",
        "    {'series': 'Target high price [%]', 'max': 50, 'reverse': False, 'weight': 1.0},\n",
        "    {'series': 'zacks', 'max': 5, 'reverse': True, 'weight': 1.2},\n",
        "    {'series': 'tipranks', 'max': 10, 'reverse': False, 'weight': 1.1},\n",
        "    {'series': 'EPS next Y', 'max': 25, 'reverse': False, 'weight': 1.2},\n",
        "    {'series': 'ROA', 'max': 10, 'reverse': False, 'weight': 1.0},\n",
        "    {'series': 'ROE', 'max': 15, 'reverse': False, 'weight': 0.8},\n",
        "    {'series': 'ROI', 'max': 20, 'reverse': False, 'weight': 1.1}]\n",
        "\n",
        "# fragments of urls that will be used to build redirections to appropriate websites\n",
        "URLS =['https://www.zacks.com/stock/quote/', 'https://www.tipranks.com/stocks/']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Program logic**"
      ],
      "metadata": {
        "id": "y5Mnt6P7_cru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading necessary tickers from a file\n",
        "filename = 'candidates.xlsx'\n",
        "tipranks = pd.read_excel(path+filename)\n",
        "tickers = list(tipranks['ticker'])\n",
        "tipranks.set_index('ticker', inplace=True)\n",
        "\n",
        "\n",
        "# Downloading necessary information from finance.yahoo\n",
        "y_f = get_data_from_yf(tickers)\n",
        "y_f = y_f[COLUMNS_YF]\n",
        "y_f.rename(columns=COLUMNS_YF_TO_CHANGE, inplace=True)\n",
        "\n",
        "\n",
        "# Downloading necessary information from finviz\n",
        "fin = get_data_from_finviz(tickers)\n",
        "fin = fin[COLUMNS_FIN]\n",
        "\n",
        "\n",
        "# Downloading necessary information from financialmodelingprep\n",
        "financialmodelin = get_data_from_financialmodeling(tickers, fin_apikey)\n",
        "financialmodelin.drop(columns='date', inplace=True)\n",
        "financialmodelin.rename(columns=COLUMNS_FINMOD_TO_CHANGE, inplace=True)\n",
        "\n",
        "\n",
        "# Downloading necessary information from zacks\n",
        "zacks = get_data_from_zacks(tickers)\n",
        "\n",
        "# redirections to appropriate websites\n",
        "www = go_to_url(tickers, URLS)\n",
        "\n",
        "# combining data from all sources\n",
        "asset = pd.concat([y_f, zacks, tipranks, fin, financialmodelin, www], axis=1)\n",
        "\n",
        "\n",
        "# converting selected columns to the appropriate numeric format\n",
        "conversion_to_number(asset, COLUMNS_FIN[1:])\n",
        "conversion_to_percent(asset, COLUMNS_TO_PERCENT)\n",
        "\n",
        "\n",
        "# normalization of selected columns\n",
        "normalized_values = {}\n",
        "for parameters in PARAMETERS_FOR_RANKING:\n",
        "  series = asset[parameters['series']]\n",
        "  max= parameters['max']\n",
        "  reverse = parameters['reverse']\n",
        "  normalized = norm(series, max, reverse)\n",
        "  normalized_values[parameters['series']] = normalized\n",
        "\n",
        "\n",
        "# creating a ranking\n",
        "ranking = sum(normalized_values.values())\n",
        "ranking.name = 'Ranking'\n",
        "\n",
        "\n",
        "# combining the ranking with the rest of the data\n",
        "stock_ranking = pd.concat([asset, ranking], axis=1)\n",
        "\n",
        "#selection of columns to show\n",
        "stock_ranking = stock_ranking[COLUMNS_TO_SHOW]\n",
        "\n",
        "# saving the result to an '.xlsx' file on disk\n",
        "stock_ranking.to_excel(path + 'ranking_' + filename)"
      ],
      "metadata": {
        "id": "pKTW__KAhsiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Additional functionality - outside the main program logic**"
      ],
      "metadata": {
        "id": "EF_f_pmrFik2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# urls addresses of the finviz website with a list of companies selected on the basis of given parameters\n",
        "urls = ['https://finviz.com/screener.ashx?v=111&f=an_recom_buybetter,fa_eps5years_o5,fa_epsyoy_o20,fa_epsyoy1_o5,fa_pe_u35,targetprice_a30',\n",
        "       'https://finviz.com/screener.ashx?v=111&f=an_recom_buybetter,fa_eps5years_o5,fa_epsyoy_o20,fa_epsyoy1_o5,fa_pe_u35,targetprice_a30&r=21']\n",
        "\n",
        "# downloading appropriate tickers and saving to disk\n",
        "tic = get_selected_tickers_from_finviz(urls)\n",
        "tic.to_excel(path + 'tickers_from_finviz.xlsx')"
      ],
      "metadata": {
        "id": "G2dWqu8airtJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnPKWL2VpkZimk7wirg1xa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}